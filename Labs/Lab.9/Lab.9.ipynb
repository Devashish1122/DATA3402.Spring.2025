{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 9- Deep Learning Model\n",
    "\n",
    "This lab is meant to get you started in using Keras to design Deep Neural Networks. The goal here is to simply repeat your previous lab, but with DNNs.\n",
    "\n",
    "Let's start with reading the data, like before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\r\n",
      "\r\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\r\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\r\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\r\n",
      "\u001b[31m   \u001b[0m install.\r\n",
      "\u001b[31m   \u001b[0m \r\n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\r\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\r\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\r\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\r\n",
      "\u001b[31m   \u001b[0m \r\n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\r\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\r\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\r\n",
      "\u001b[31m   \u001b[0m \r\n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\r\n",
      "\r\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\r\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\r\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install pandas\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "filename=\"../Lab.7/SUSY.csv\"\n",
    "VarNames=[\"signal\", \"l_1_pT\", \"l_1_eta\",\"l_1_phi\", \"l_2_pT\", \"l_2_eta\", \"l_2_phi\", \"MET\", \"MET_phi\", \"MET_rel\", \"axial_MET\", \"M_R\", \"M_TR_2\", \"R\", \"MT2\", \"S_R\", \"M_Delta_R\", \"dPhi_r_b\", \"cos_theta_r1\"]\n",
    "RawNames=[\"l_1_pT\", \"l_1_eta\",\"l_1_phi\", \"l_2_pT\", \"l_2_eta\", \"l_2_phi\",\"MET\", \"MET_phi\", \"MET_rel\", \"axial_MET\"]\n",
    "FeatureNames=[\"M_R\", \"M_TR_2\", \"R\", \"MT2\", \"S_R\", \"M_Delta_R\", \"dPhi_r_b\", \"cos_theta_r1\"]\n",
    "\n",
    "df = pd.read_csv(filename, dtype='float64', names=VarNames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets define training and test samples. Note that DNNs take very long to train, so for testing purposes we will use only about 10% of the 5 million events in the training/validation sample. Once you get everything working, make the final version of your plots with the full sample. \n",
    "\n",
    "Also note that Keras had trouble with the Pandas tensors, so after doing all of the nice manipulation that Pandas enables, we convert the Tensor to a regular numpy tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m N_Max\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m550000\u001b[39m\n\u001b[1;32m      2\u001b[0m N_Train\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500000\u001b[39m\n\u001b[0;32m----> 4\u001b[0m Train_Sample\u001b[38;5;241m=\u001b[39m\u001b[43mdf\u001b[49m[:N_Train]\n\u001b[1;32m      5\u001b[0m Test_Sample\u001b[38;5;241m=\u001b[39mdf[N_Train:N_Max]\n\u001b[1;32m      7\u001b[0m X_Train\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39marray(Train_Sample[VarNames[\u001b[38;5;241m1\u001b[39m:]])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "N_Max=550000\n",
    "N_Train=500000\n",
    "\n",
    "Train_Sample=df[:N_Train]\n",
    "Test_Sample=df[N_Train:N_Max]\n",
    "\n",
    "X_Train=np.array(Train_Sample[VarNames[1:]])\n",
    "y_Train=np.array(Train_Sample[\"signal\"])\n",
    "\n",
    "X_Test=np.array(Test_Sample[VarNames[1:]])\n",
    "y_Test=np.array(Test_Sample[\"signal\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "You will need to create several models and make sure they are properly trained. Write a function that takes this history and plots the values versus epoch. For every model that you train in the remainder of this lab, assess:\n",
    "\n",
    "* Has you model's performance plateaued? If not train for more epochs. \n",
    "* Compare the performance on training versus test sample. Are you over training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Following the original paper (see lab 7), make a comparison of the performance (using ROC curves and AUC) between models trained with raw, features, and raw+features data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Design and implement at least 3 different DNN models. Train them and compare performance. You may try different architectures, loss functions, and optimizers to see if there is an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Repeat exercise 4 from Lab 8, adding your best performing DNN as one of the models.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character '…' (U+2026) (2230949777.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 23\u001b[0;36m\u001b[0m\n\u001b[0;31m    y_Test = np.array(Test……\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character '…' (U+2026)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.metrics import roc_curve, auc, precision_score, recall_score, f1_score, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "filename = \"SUSY.csv\"\n",
    "VarNames = [\"signal\", \"l_1_pT\", \"l_1_eta\", \"l_1_phi\", \"l_2_pT\", \"l_2_eta\", \"l_2_phi\", \n",
    "            \"MET\", \"MET_phi\", \"MET_rel\", \"axial_MET\", \"M_R\", \"M_TR_2\", \"R\", \"MT2\", \n",
    "            \"S_R\", \"M_Delta_R\", \"dPhi_r_b\", \"cos_theta_r1\"]\n",
    "df = pd.read_csv(filename, dtype='float64', names=VarNames)\n",
    "\n",
    "N_Max = 550000\n",
    "N_Train = 500000\n",
    "Train_Sample = df[:N_Train]\n",
    "Test_Sample = df[N_Train:N_Max]\n",
    "X_Train = np.array(Train_Sample[VarNames[1:]]) \n",
    "y_Train = np.array(Train_Sample[\"signal\"])\n",
    "X_Test = np.array(Test_Sample[VarNames[1:]])\n",
    "y_Test = np.array(Test……\n",
    "\n",
    "def create_best_dnn(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "classifiers = {\n",
    "    'Default LDA': LinearDiscriminantAnalysis(),\n",
    "    'Balanced LDA': LinearDiscriminantAnalysis(class_weight='balanced'),\n",
    "    'Best DNN': create_best_dnn(X_Train.shape[1])\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    if name == 'Best DNN':\n",
    "        clf.fit(X_Train, y_Train, \n",
    "                validation_data=(X_Test, y_Test),\n",
    "                epochs=10, batch_size=128, verbose=1)\n",
    "        y_pred_proba = clf.predict(X_Test).ravel()\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "    else:\n",
    "        clf.fit(X_Train, y_Train)\n",
    "        y_pred_proba = clf.decision_function(X_Test)\n",
    "        y_pred = clf.predict(X_Test)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_Test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    precision = precision_score(y_Test, y_pred)\n",
    "    recall = recall_score(y_Test, y_pred) \n",
    "    f1 = f1_score(y_Test, y_pred)\n",
    "    accuracy = accuracy_score(y_Test, y_pred)\n",
    "    \n",
    "    tn = np.sum((y_Test == 0) & (y_pred == 0))\n",
    "    fp = np.sum((y_Test == 0) & (y_pred == 1))\n",
    "    fpr_default = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'TPR (Recall)': recall,\n",
    "        'FPR': fpr_default,\n",
    "        'ROC AUC': roc_auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Accuracy': accuracy,\n",
    "        'Maximal Significance': roc_auc\n",
    "    })\n",
    "    \n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves: LDA vs. Best DNN')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "results_df = pd.DataFrame(results).round(3)\n",
    "print(\"\\nMetrics Table for Exercise 4:\")\n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
